{
  "create_time": 1470013200000,
  "content": "\n　　在预测未来这一点上，计算机正变得越来越擅长。在许多方面里，计算机甚至已经超过人类了。例如，亚马逊能通过计算知道你可能会买什么，视频网站 Netflix 知道你接下去会想看什么视频，气象学家能通过数据分析提前知道十天后的天气。 \n　　现在，有一群科学家正在研究通过机器学习，来计算出谁将有可能在未来进行犯罪。听上去是不是有点像科幻故事的情节。科幻动漫迷们一定记得《心理测量者》这部漫画。 p style=\"text-align: center;\"> p align=\"center\">《心理测量者》动画 \n　　《心理测量者》描述的是一个人类内心活动均能够数值化的科技时代，同样能被量化的，还有每个人的“犯罪系数”。人类所有的感情、欲望、社会病态心理倾向等全部被监控摄像头记录并管理，每个心理状态和个性倾向所衡量的值，通称 PSYCHO-PASS，也就是片名。它被用来判定人们的思想状态、个人精神本身。通过计算这些数值，系统可以自主断定一个人最理想的工作，感情，心理压力，甚至犯罪意图。 \n　　人们需要不断地保证自己的指数在正常范围，否则会被系统认为是潜在犯，将会被“矫正”。动漫故事里的情节对于我们来说，或许不再难以实现。宾夕法尼亚大学（University of Pennsylvania）统计学教授理查德·伯克（Richard Berk）和他的研究团队就在开发一种新的算法，希望能预测哪些人会在未来犯罪的风险高。 \n　　在此之前，伯克的算法已经能帮助监狱确定该把哪些犯人关到高度警戒区。假释部门用他的工具判断该对哪类假释人员采取更严格的监视手段，警官则用来预测曾因家庭暴力被捕的人是否会再次犯罪。他还编写过一个算法，可以告诉美国职业安全与卫生管理局(Occupational Safety and Health Administration)，哪些工作场所可能违反安全方面的规定。 \n　　机器学习能提前预测犯罪发生 \n　　先来看看伯克的算法是如何做到预测犯罪的。参照之前谷歌旗下人工智能系统“阿尔法狗”。在完成打败韩国棋手李世石前，谷歌从网络上喂给“阿尔法狗”上万的棋局数据，让其学习如何以最优的策略进行下棋，同时还让“阿尔法狗”自己进行训练，提升自己。 \n　　伯克的算法与“阿尔法狗”类似。在今年 2 月份，伯克和宾夕法尼亚大学的心理学家苏珊·索伦森（Susan Sorenson）共同将研究发表在了《实证法律研究》的杂志上。他们收集了从 2009 年到 2013 年所有发生家庭暴力的案例，约有 10 万件。接着，他们使用了机器学习的方法，将这些数据喂给电脑程序，包括年龄、性别、邮编、第一次犯罪的年龄以及一长串先前可能相关的犯罪记录。比如酒后驾车、虐待动物、涉枪犯罪等。但伯克并没有将种族这个信息作为输入信息选项喂给计算机。 p style=\"text-align: center;\"> p align=\"center\">伯克的研究：年龄和犯罪的相关性 \n　　三分之二的案件信息，由研究人员输入来“训练”系统，并让其推测结果，这些人是否会第二次进行家庭暴力犯罪。另外三分之一的数据，他们则用来测试系统。这部分案件，计算只能知道和提审法官一样多的信息，然后得出结论，看谁会因为二次犯罪而被捕。 \n　　通过机器学习，警方能够很容易地锁定哪些人重复犯罪，需要监禁哪些二次犯罪风险较高的人。伯克在文章里说，目前，由于涉嫌家庭暴力的罪犯有一半是被释放的，这给警察和政府对他们的监控带来了很高的成本。他们的研究挑战就是在释放的案例中，推测哪些人二次犯罪的风险较低，从而能抽出更多的警力监控那些犯罪风险较高的人。与法官的判断进行对比的结果是：法官判断有 20% 的人会再犯，而计算机给出的比例仅为 10%。 p style=\"text-align: center;\"> p align=\"center\">伯克的研究：预测犯罪的正确率结果 \n　　除了家庭暴力的案件研究外，伯克在假释和缓刑方面的算法已经得到美国费城政府的使用。伯克把费城市所有缓刑和假释的人都划分到了高犯罪风险、中犯罪风险和低犯罪风险三个档次里。对于系统认定为低犯罪风险的人，市政府大幅降低了对他们的监视强度。 \n　　该算法还运用在马里兰州和宾夕法尼亚州全州范围内的假释体系里。据彭博社拿到的数据分析，在 2011 年和 2014 年之间，大约有 15% 的假释申请人基于风险评分得到了不同的假释裁决。和以往的假释人员相比，在此期间获假释的人员被再次逮捕的情况大大减少。所以结论是：伯克的软件帮助州政府做出了更明智的决策。 \n　　政府部分的使用，也给伯克带来了更多的信心。现在他正在着手建立一个新的系统：伯克想基于环境以及新生儿父母的过往，在一个人出生的时候就预测出他/她是否会在年满 18 岁时犯罪。 \n　　机器算法能否代替人类做出判决 \n　　在伯克的算法出现前，在司法部分利用计算机来处理案件，在美国已有先例。上个世纪 90 年代，纽约市就曾用数据信息来预测哪些地铁站是犯罪高发区。现在，随着算法越来越先进和熟练，甚至已经开始有商业公司与政府展开合作。比如，由密歇根一家名为 Northpointe 公司开发的系统 Compas。根据该公司的介绍，在被这款软件认定为高犯罪风险的人里面，大约有 70% 的人被再次逮捕。 \n　　尽管这些系统给政府机构提高效率，但仍受到了许多批评和质疑。首先，数据安全问题。机器学习需要基于大量的数据进行分析和学习。涉及犯罪的数据又是高度隐私的数据，因此很多人担心数据是否会泄露。伯克在接受采访时曾表示，自己仅使用对公众开放的数据，即已经被捕的犯罪数据。他训练的系统不会窥视和使用普通人的数据。但他的新算法，在婴儿出生时就判断是否会在年满 18 岁时犯罪可能会受到限制。因为一个人大部分的个人信息都分散在许多机构，要收集这么多的信息，会非常困难。 \n　　其次，准确性问题。这也是算法遇到的最大问题，也是被人诟病最多的问题。因为算法都是基于历史犯罪统计数据来预测未来的犯罪行为，因此有可能会把过去的执法模式和认为特定人群（几乎全部是穷人和非白人）有犯罪倾向的想法画上等号。伯克也承认了系统会有这样的风险。还有更为直观的案例。根据国外新闻网站 ProPublica 发布的调查报告，他们查看了佛罗里达州一家法院在 2013 年和 2014 年使用过的 Compas 风险评分，发现黑人被标注为高犯罪风险、但后来并没有犯罪的可能性几乎是白人的两倍，同时，当都被评定为低犯罪风险时，白人再次犯罪的情况则比黑人常见得多。 \n　　第三，算法是否应该公开。因为涉及商业利益，Northpoint 并没有将自己的算法公开，这也导致许多人认为这个系统存在猫腻。伯克公开了自己的算法，同时也攻击了该公司的做法。最后，过度依赖的问题。现在很多政府机构开始依赖算法提供的结果。这也是伯克担心的问题之一。他在接受彭博社采访时说，如果系统没有经过科学的认证和测试，那质疑就会随之而来。尽管机器学习能做出决定，但要从目前情况来看，让系统代替人类做出决定可能还为时过早。　　机器学习能提前预测犯罪发生　　机器算法能否代替人类做出判决",
  "title": "《心理测量者》不再科幻，美国尝试用人工智能预测犯罪",
  "creator": "itwriter"
}
